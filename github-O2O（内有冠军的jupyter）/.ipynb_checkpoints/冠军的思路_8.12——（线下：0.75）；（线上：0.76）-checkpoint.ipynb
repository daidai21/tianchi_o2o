{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0,
     48,
     70,
     75,
     80,
     82,
     86,
     90,
     94,
     98,
     102,
     106,
     110,
     115,
     117,
     125,
     153,
     166,
     175,
     180,
     203
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###库#####################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import graphviz\n",
    "from time import time\n",
    "import random\n",
    "import pydotplus \n",
    "import os\n",
    "import re\n",
    "import jieba\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体\n",
    "mpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  #'all'|'last'|'last_expr'|'none'\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "input_path = '../input/'\n",
    "submi_path = '../submision/'\n",
    "\n",
    "########################################################################\n",
    "###特征预处理\n",
    "def age_group(age):\n",
    "    #用法：ori_data_28['age_group'] = ori_data_28.age.apply(age_group)\n",
    "    if (age>=0) and (age<=10):\n",
    "        return 0\n",
    "    elif (age>10) and (age<=20):\n",
    "        return 1\n",
    "    elif (age>20) and (age<=30):\n",
    "        return 2\n",
    "    elif (age>30) and (age<=40):\n",
    "        return 3\n",
    "    elif (age>4) and (age<=50):\n",
    "        return 4\n",
    "    elif (age>50) and (age<=60):\n",
    "        return 5\n",
    "    elif (age>60) and (age<=70):\n",
    "        return 6\n",
    "    elif (age>70) and (age<=80):\n",
    "        return 7\n",
    "    elif (age>80) and (age<=90):\n",
    "        return 8\n",
    "    elif (age>90):\n",
    "        return 9\n",
    "def encode_count(df, encoder_list):\n",
    "    lbl = LabelEncoder()\n",
    "    for i in range(0, len(encoder_list)):\n",
    "        df[[encoder_list[i]]] = lbl.fit_transform(df[[encoder_list[i]]])\n",
    "    return df\n",
    "def encode_onehot(df, oneHot_list):\n",
    "    for i in range(0, len(oneHot_list)):\n",
    "        feature_df = pd.get_dummies(df[oneHot_list[i]], prefix=oneHot_list[i])\n",
    "        df = pd.concat([df.drop([oneHot_list[i]], axis=1), feature_df], axis=1)\n",
    "    return df\n",
    "def normalize(df, normalize_list):\n",
    "    scaler = StandardScaler()\n",
    "    for i in range(0, len(normalize_list)):\n",
    "        df[[normalize_list[i]]] = scaler.fit_transform(df[[normalize_list[i]]])\n",
    "    return df\n",
    "###制作统计特征\n",
    "def feat_nunique(df_tar, df_fea, grou, stati, name, na=0):\n",
    "    add_tem = df_fea.groupby(grou)[stati].nunique().reset_index().rename(columns={stati[0]: name[0]})\n",
    "    df_tar = pd.merge(df_tar, add_tem, on=grou, how='left').fillna(na)\n",
    "    return df_tar\n",
    "def feat_mode(df_tar, df_fea, grou, stati, name, na=0):\n",
    "    add_tem = df_fea.groupby(grou)[stati].mode().reset_index().rename(columns={stati[0]: name[0]})\n",
    "    df_tar = pd.merge(df_tar, add_tem, on=grou, how='left').fillna(na)\n",
    "    return df_tar\n",
    "def feat_count(df_tar, df_fea, grou, stati, name, na=0):\n",
    "    add_tem = df_fea.groupby(grou)[stati].count().reset_index().rename(columns={stati[0]: name[0]})\n",
    "    df_tar = pd.merge(df_tar, add_tem, on=grou, how='left').fillna(na)\n",
    "    return df_tar\n",
    "def feat_sum(df_tar, df_fea, grou, stati, name, na=0):\n",
    "    add_tem = df_fea.groupby(grou)[stati].sum().reset_index().rename(columns={stati[0]: name[0]})\n",
    "    df_tar = pd.merge(df_tar, add_tem, on=grou, how='left').fillna(na)\n",
    "    return df_tar\n",
    "def feat_mean(df_tar, df_fea, grou, stati, name, na=0):\n",
    "    add_tem = df_fea.groupby(grou)[stati].mean().reset_index().rename(columns={stati[0]: name[0]})\n",
    "    df_tar = pd.merge(df_tar, add_tem, on=grou, how='left').fillna(na)\n",
    "    return df_tar\n",
    "def feat_max(df_tar, df_fea, grou, stati, name, na=0):\n",
    "    add_tem = df_fea.groupby(grou)[stati].max().reset_index().rename(columns={stati[0]: name[0]})\n",
    "    df_tar = pd.merge(df_tar, add_tem, on=grou, how='left').fillna(na)\n",
    "    return df_tar\n",
    "def feat_min(df_tar, df_fea, grou, stati, name, na=0):\n",
    "    add_tem = df_fea.groupby(grou)[stati].min().reset_index().rename(columns={stati[0]: name[0]})\n",
    "    df_tar = pd.merge(df_tar, add_tem, on=grou, how='left').fillna(na)\n",
    "    return df_tar\n",
    "###特征选择\n",
    "def Tree_feature_select(X_train, y_train, X_val, y_val, X_test, sel_num): \n",
    "     ##最简单最常用\n",
    "    clf = lgb.LGBMClassifier(n_estimators=10000,\n",
    "                             learning_rate=0.06,\n",
    "                             max_depth=5,\n",
    "                             num_leaves=30,\n",
    "                             objective='binary',\n",
    "                             subsample=0.9,\n",
    "                             sub_feature=0.9,\n",
    "                            )\n",
    "    clf = clf.fit(X_train, y_train, \n",
    "                  eval_set=[(X_val, y_val)], eval_metric='binary_logloss',\n",
    "                  early_stopping_rounds=100, verbose = 500, \n",
    "                 )\n",
    "\n",
    "    if type(X_train) is pd.core.frame.DataFrame:\n",
    "        print('type(X_train) is DataFrame')\n",
    "        feat_impo = sorted(zip(X_train.columns, clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "        sel_list = [feat[0] for feat in feat_impo[0: sel_num]]\n",
    "        X_train_sel = X_train[sel_list]\n",
    "        X_val_sel = X_val[sel_list]\n",
    "        X_test_sel = X_test[sel_list]\n",
    "    else:\n",
    "        if type(X_train) is np.ndarray:\n",
    "            print('type(X_train) is ndarray')\n",
    "            feat_impo = sorted(zip(range(0, len(X_train[0])), clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "        elif type(X_train) is csr_matrix:\n",
    "            print('type(X_train) is csr_matrix')\n",
    "            feat_impo = sorted(zip(range(0, X_train.get_shape()[1]), clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        sel_list = [feat[0] for feat in feat_impo[0: sel_num]]\n",
    "        X_train_sel = X_train[:, sel_list]\n",
    "        X_val_sel = X_val[:, sel_list]\n",
    "        X_test_sel = X_test[sel_list]\n",
    "        \n",
    "    print(\"sel_num is:\", sel_num)\n",
    "    return feat_impo, X_train_sel, X_val_sel, X_test_sel\n",
    "def RFECV_feature_sel(X_train, y_train, X_val, X_test):  \n",
    "    ##天池的大佬经常使用！！！\n",
    "    ###clf可以随便换！！！\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    selor = RFECV(clf, step=1, cv=3)\n",
    "    selor = selor.fit(X_train, y_train)\n",
    "\n",
    "    X_train_sel = selor.transform(X_train)\n",
    "    X_val_sel = selor.transform(X_val)\n",
    "    X_test_sel = selor.transform(X_test)\n",
    "    \n",
    "    return selor, X_train_sel, X_val_sel, X_test_sel\n",
    "###降维\n",
    "def PCA_decomposition(X_train, X_test, num):\n",
    "    ##注pca不支持稀疏输入\n",
    "    pca = PCA(num)\n",
    "    pca.fit(X_train)\n",
    "    low_X_train = pca.transform(X_train) \n",
    "    low_X_test = pca.transform(X_test) \n",
    "\n",
    "    return pca, low_X_train, low_X_test\n",
    "###提取cnn卷积特征\n",
    "def get_activation(nn_model, layer, X_origin):\n",
    "    get_activations = bk.function([nn_model.layers[0].input, bk.learning_phase()], [nn_model.layers[layer].output])\n",
    "    activations=get_activations([X_origin, 0])\n",
    "    return activations\n",
    "###评价矩阵\n",
    "def evaluate_matrix(y_test_class, y_pred_prob):\n",
    "    y_pred_prob = [array[1] for array in y_pred_prob]  #因为sklearn输出每个类别的概率，手动选择1类\n",
    "    y_pred_class = [1 if y>=0.50 else 0 for y in y_pred_prob]\n",
    "\n",
    "\n",
    "    matrix = confusion_matrix(y_test_class, y_pred_class)\n",
    "    print(matrix)\n",
    "\n",
    "    if len(set(y_test_class)) == 2:  #二分类\n",
    "        print('二分类')\n",
    "        print('f1 score  ：', f1_score(y_test_class, y_pred_class))  \n",
    "        print('precision：', precision_score(y_test_class, y_pred_class))\n",
    "        print('recall：', recall_score(y_test_class, y_pred_class))\n",
    "        print('accuracy：', accuracy_score(y_test_class, y_pred_class))\n",
    "        print('AUC：', roc_auc_score(y_test_class, y_pred_prob))\n",
    "    elif len(set(y_test_class)) > 2:  #多分类\n",
    "        print('多分类')\n",
    "        print('f1 score  ：', f1_score(y_test_class, y_pred_class, average='macro'))  \n",
    "        print('precision：', precision_score(y_test_class, y_pred_class, average='macro'))\n",
    "        print('recall：', recall_score(y_test_class, y_pred_class, average='macro'))\n",
    "        print('accuracy：', accuracy_score(y_test_class, y_pred_class))\n",
    "        pass\n",
    "###jieba分词调整\n",
    "def __jieba_expend_dict():\n",
    "#         ###增加词典\n",
    "#         jieba.add_word('背骶尾部')\n",
    "\n",
    "#         ###调整词典\n",
    "#         jieba.suggest_freq('撞到', True)\n",
    "\n",
    "#         jieba.suggest_freq(('致', '右'), tune=False)\n",
    "    pass\n",
    "__jieba_expend_dict()\n",
    "\n",
    "###其他工具函数\n",
    "# pickle.dump(ori_data_28, open(input_path + 'ori_data_28.pkl', 'wb'))\n",
    "# ori_data_28 = pickle.load(open(input_path + 'ori_data_28.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_train: (11429826, 7)\n",
      "off_train: (1754884, 7)\n",
      "off_test: (113640, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Action</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13740231</td>\n",
       "      <td>18907</td>\n",
       "      <td>2</td>\n",
       "      <td>100017492</td>\n",
       "      <td>500:50</td>\n",
       "      <td>20160513.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13740231</td>\n",
       "      <td>34805</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20160321.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Action  Coupon_id Discount_rate  Date_received  \\\n",
       "0  13740231        18907       2  100017492        500:50     20160513.0   \n",
       "1  13740231        34805       1         -1            -1           -1.0   \n",
       "\n",
       "         Date  \n",
       "0        -1.0  \n",
       "1  20160321.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632       -1.0            -1       0.0           -1.0   \n",
       "1  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "\n",
       "         Date  \n",
       "0  20160217.0  \n",
       "1        -1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4129537</td>\n",
       "      <td>450</td>\n",
       "      <td>9983</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6949378</td>\n",
       "      <td>1300</td>\n",
       "      <td>3429</td>\n",
       "      <td>30:5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20160706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received\n",
       "0  4129537          450       9983          30:5       1.0       20160712\n",
       "1  6949378         1300       3429          30:5      -1.0       20160706"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "on_train:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11429826 entries, 0 to 11429825\n",
      "Data columns (total 7 columns):\n",
      "User_id          int64\n",
      "Merchant_id      int64\n",
      "Action           int64\n",
      "Coupon_id        object\n",
      "Discount_rate    object\n",
      "Date_received    float64\n",
      "Date             float64\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 610.4+ MB\n",
      "\n",
      "\n",
      "off_train:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1754884 entries, 0 to 1754883\n",
      "Data columns (total 7 columns):\n",
      "User_id          int64\n",
      "Merchant_id      int64\n",
      "Coupon_id        float64\n",
      "Discount_rate    object\n",
      "Distance         float64\n",
      "Date_received    float64\n",
      "Date             float64\n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 93.7+ MB\n",
      "\n",
      "\n",
      "off_test:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113640 entries, 0 to 113639\n",
      "Data columns (total 6 columns):\n",
      "User_id          113640 non-null int64\n",
      "Merchant_id      113640 non-null int64\n",
      "Coupon_id        113640 non-null int64\n",
      "Discount_rate    113640 non-null object\n",
      "Distance         113640 non-null float64\n",
      "Date_received    113640 non-null int64\n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "on_train = pd.read_csv(input_path + 'ccf_online_stage1_train.csv')\n",
    "off_train = pd.read_csv(input_path + 'ccf_offline_stage1_train.csv')\n",
    "off_test = pd.read_csv(input_path + 'ccf_offline_stage1_test_revised.csv')\n",
    "\n",
    "on_train = on_train.fillna(-1)\n",
    "off_train = off_train.fillna(-1)\n",
    "off_test = off_test.fillna(-1)\n",
    "\n",
    "\n",
    "print('on_train:', on_train.shape)\n",
    "print('off_train:', off_train.shape)\n",
    "print('off_test:', off_test.shape)\n",
    "\n",
    "on_train.head(2)\n",
    "off_train.head(2)\n",
    "off_test.head(2)\n",
    "\n",
    "print('\\n')\n",
    "print('on_train:')\n",
    "on_train.info()\n",
    "\n",
    "print('\\n')\n",
    "print('off_train:')\n",
    "off_train.info()\n",
    "\n",
    "print('\\n')\n",
    "print('off_test:')\n",
    "off_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, '150:20', '20:1', '200:20', '30:5', '50:10', '10:5', '100:10',\n",
       "       '200:30', '20:5', '30:10', '50:5', '150:10', '100:30', '200:50',\n",
       "       '100:50', '300:30', '50:20', '0.9', '10:1', '30:1', '0.95',\n",
       "       '100:5', '5:1', '100:20', '0.8', '50:1', '200:10', '300:20',\n",
       "       '100:1', '150:30', '300:50', '20:10', '0.85', '0.6', '150:50',\n",
       "       '0.75', '0.5', '200:5', '0.7', '30:20', '300:10', '0.2', '50:30',\n",
       "       '200:100', '150:5'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., -1.,  2., 10.,  4.,  7.,  9.,  3.,  5.,  6.,  8.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毫无疑问，基本上都是“满多少，减多少”的优惠券\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xeba14e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看看哪些优惠券是经常被领的\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30:5</td>\n",
       "      <td>270712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100:10</td>\n",
       "      <td>182554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200:20</td>\n",
       "      <td>111046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20:5</td>\n",
       "      <td>91013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20:1</td>\n",
       "      <td>51705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50:5</td>\n",
       "      <td>47379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100:30</td>\n",
       "      <td>38196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200:30</td>\n",
       "      <td>29327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300:30</td>\n",
       "      <td>28979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50:10</td>\n",
       "      <td>28452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10:5</td>\n",
       "      <td>25925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.95</td>\n",
       "      <td>20568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10:1</td>\n",
       "      <td>17842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30:1</td>\n",
       "      <td>17654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150:20</td>\n",
       "      <td>17437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1\n",
       "0     30:5  270712\n",
       "1   100:10  182554\n",
       "2   200:20  111046\n",
       "3     20:5   91013\n",
       "4     20:1   51705\n",
       "5     50:5   47379\n",
       "6   100:30   38196\n",
       "7   200:30   29327\n",
       "8   300:30   28979\n",
       "9    50:10   28452\n",
       "10    10:5   25925\n",
       "11    0.95   20568\n",
       "12    10:1   17842\n",
       "13    30:1   17654\n",
       "14  150:20   17437"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xebf6588>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看看哪些优惠券是经常被领的\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30:5</td>\n",
       "      <td>23368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20:5</td>\n",
       "      <td>12471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20:1</td>\n",
       "      <td>8280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100:10</td>\n",
       "      <td>5550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10:1</td>\n",
       "      <td>4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10:5</td>\n",
       "      <td>3302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50:5</td>\n",
       "      <td>3073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30:1</td>\n",
       "      <td>2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.95</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200:20</td>\n",
       "      <td>1731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50:10</td>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100:20</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100:30</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5:1</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.8</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1\n",
       "0     30:5  23368\n",
       "1     20:5  12471\n",
       "2     20:1   8280\n",
       "3   100:10   5550\n",
       "4     10:1   4054\n",
       "5     10:5   3302\n",
       "6     50:5   3073\n",
       "7     30:1   2561\n",
       "8     0.95   2521\n",
       "9   200:20   1731\n",
       "10   50:10   1242\n",
       "11  100:20   1047\n",
       "12  100:30   1033\n",
       "13     5:1    641\n",
       "14     0.8    635"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###优惠券和距离\n",
    "off_train.Discount_rate.unique()\n",
    "off_train.Distance.unique()\n",
    "\n",
    "print('毫无疑问，基本上都是“满多少，减多少”的优惠券')\n",
    "\n",
    "#每种类型消费券出现的次数\n",
    "X = []\n",
    "Y = []\n",
    "for rate_type in (off_train.Discount_rate.unique()):\n",
    "    if rate_type != -1:\n",
    "        x = rate_type\n",
    "        y = off_train[off_train.Discount_rate == rate_type].Discount_rate.count()\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "df_tem = pd.DataFrame([X, Y]).T\n",
    "df_tem = df_tem.sort_values(by=1, ascending = False).reset_index(drop=True)\n",
    "\n",
    "df_tem[1].plot()\n",
    "plt.show()\n",
    "\n",
    "print('看看哪些优惠券是经常被领的')\n",
    "df_tem.shape\n",
    "df_tem.head(15)\n",
    "\n",
    "\n",
    "##优惠券核销的次数\n",
    "X = []\n",
    "Y = []\n",
    "for rate_type in (off_train.Discount_rate.unique()):\n",
    "    if rate_type != -1:\n",
    "        x = rate_type\n",
    "        y = off_train[(off_train.Discount_rate == rate_type) & (off_train.Date != -1)].Discount_rate.count()\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "df_tem = pd.DataFrame([X, Y]).T\n",
    "df_tem = df_tem.sort_values(by=1, ascending = False).reset_index(drop=True)\n",
    "\n",
    "df_tem[1].plot()\n",
    "plt.show()\n",
    "\n",
    "print('看看哪些优惠券是经常被领的')\n",
    "df_tem.shape\n",
    "df_tem.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>20160214.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>20160607.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>20160125.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Date_received  count\n",
       "0        4     20160214.0      1\n",
       "1        4     20160607.0      1\n",
       "2       35     20160129.0      2\n",
       "3       35     20160130.0      2\n",
       "4       36     20160125.0      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>20160228.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>687</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>687</td>\n",
       "      <td>20160402.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>696</td>\n",
       "      <td>20160413.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id        Date  count\n",
       "0      184  20160228.0      1\n",
       "1      417  20160412.0      1\n",
       "2      687  20160130.0      1\n",
       "3      687  20160402.0      1\n",
       "4      696  20160413.0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在这些领了券的人当中，每一天倒是会领很多次，但是基本上一天当中只会消费一次\n"
     ]
    }
   ],
   "source": [
    "coupon_byDate = off_train[off_train['Date_received'] != -1].groupby(['User_id', 'Date_received'], as_index=False)[['Merchant_id']].count()\n",
    "coupon_byDate.columns = ['User_id', 'Date_received','count']\n",
    "\n",
    "buy_byDate = off_train[(off_train['Date'] != -1) & (off_train['Date_received'] != -1)].groupby(['User_id', 'Date'], as_index=False)[['Merchant_id']].count()\n",
    "buy_byDate.columns = ['User_id', 'Date','count']\n",
    "\n",
    "coupon_byDate.head()\n",
    "buy_byDate.head()\n",
    "\n",
    "print('在这些领了券的人当中，每一天倒是会领很多次，但是基本上一天当中只会消费一次')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户： 2\n",
      "商店： 1\n",
      "优惠券： 932\n",
      "\n",
      "\n",
      "测试集上的数据，基本train上都有覆盖\n"
     ]
    }
   ],
   "source": [
    "# 测试集中出现，但训练集没出现\n",
    "\n",
    "print('用户：', len(set(off_test.User_id) - set(off_train.User_id)))\n",
    "print('商店：', len(set(off_test.Merchant_id) - set(off_train.Merchant_id)))\n",
    "print('优惠券：', len(set(off_test.Coupon_id) - set(off_train.Coupon_id)))\n",
    "\n",
    "print('\\n')\n",
    "print('测试集上的数据，基本train上都有覆盖')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75382, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(977900, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###正样本\n",
    "posi_sample_offLine = off_train[(off_train.Coupon_id != -1) & (off_train.Date != -1)]\n",
    "posi_sample_offLine.shape\n",
    "\n",
    "###负样本\n",
    "navi_sample_offLine = off_train[(off_train.Coupon_id != -1) & (off_train.Date == -1)]\n",
    "navi_sample_offLine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "online训练集，领取优惠券的最早时期： 20160101.0\n",
      "online训练集，领取优惠券的最后时期： 20160615.0\n",
      "\n",
      "\n",
      "offline训练集，领取优惠券的最早时期： 20160101.0\n",
      "offline训练集，领取优惠券的最后时期： 20160615.0\n",
      "\n",
      "\n",
      "online训练集，消费的最早时期： 20160101.0\n",
      "online训练集，消费的最后时期： 20160630.0\n",
      "\n",
      "\n",
      "offline训练集，消费的最早时期： 20160101.0\n",
      "offline训练集，消费的最后时期： 20160630.0\n",
      "\n",
      "\n",
      "offline测试集，领取优惠券的最早时期： 20160701\n",
      "offline测试集，领取优惠券的最后时期： 20160731\n"
     ]
    }
   ],
   "source": [
    "tem = sorted(on_train.Date_received.unique())\n",
    "print('online训练集，领取优惠券的最早时期：', tem[1])\n",
    "print('online训练集，领取优惠券的最后时期：', tem[-1])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "tem = sorted(off_train.Date_received.unique())\n",
    "print('offline训练集，领取优惠券的最早时期：', tem[1])\n",
    "print('offline训练集，领取优惠券的最后时期：', tem[-1])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "tem = sorted(on_train.Date.unique())\n",
    "print('online训练集，消费的最早时期：', tem[1])\n",
    "print('online训练集，消费的最后时期：', tem[-1])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "tem = sorted(off_train.Date.unique())\n",
    "print('offline训练集，消费的最早时期：', tem[1])\n",
    "print('offline训练集，消费的最后时期：', tem[-1])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "tem = sorted(off_test.Date_received.unique())\n",
    "print('offline测试集，领取优惠券的最早时期：', tem[0])\n",
    "print('offline测试集，领取优惠券的最后时期：', tem[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_train:\n",
      "有优惠券， 购买商品： 216459\n",
      "有优惠券， 没有购买商品： 655898\n",
      "无优惠券， 购买商品： 10557469\n",
      "无优惠券， 没有购买商品： 0\n",
      "\n",
      "\n",
      "off_train:\n",
      "有优惠券， 购买商品： 75382\n",
      "有优惠券， 没有购买商品： 977900\n",
      "无优惠券， 购买商品： 701602\n",
      "无优惠券， 没有购买商品： 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('on_train:')\n",
    "print('有优惠券， 购买商品：', on_train[(on_train['Coupon_id'] != -1) & (on_train['Date'] != -1)].shape[0])\n",
    "print('有优惠券， 没有购买商品：', on_train[(on_train['Coupon_id'] != -1) & (on_train['Date'] == -1)].shape[0])\n",
    "print('无优惠券， 购买商品：', on_train[(on_train['Coupon_id'] == -1) & (on_train['Date'] != -1)].shape[0])\n",
    "print('无优惠券， 没有购买商品：', on_train[(on_train['Coupon_id'] == -1) & (on_train['Date'] == -1)].shape[0])\n",
    "print('\\n')\n",
    "\n",
    "print('off_train:')\n",
    "print('有优惠券， 购买商品：', off_train[(off_train['Coupon_id'] != -1) & (off_train['Date'] != -1)].shape[0])\n",
    "print('有优惠券， 没有购买商品：', off_train[(off_train['Coupon_id'] != -1) & (off_train['Date'] == -1)].shape[0])\n",
    "print('无优惠券， 购买商品：', off_train[(off_train['Coupon_id'] == -1) & (off_train['Date'] != -1)].shape[0])\n",
    "print('无优惠券， 没有购买商品：', off_train[(off_train['Coupon_id'] == -1) & (off_train['Date'] == -1)].shape[0])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_train的人数： 762858\n",
      "off_train的人数： 539438\n",
      "off_train和on_train的人数交集： 267448\n",
      "\n",
      "\n",
      "on_train的商户数： 7999\n",
      "off_train的商户数： 8415\n",
      "off_train和on_train的商户数交集： 0\n",
      "\n",
      "\n",
      "on_train的优惠券数： 27748\n",
      "off_train的优惠券数： 9739\n",
      "off_train和on_train的优惠券数交集： 1\n",
      "\n",
      "\n",
      "off_test的人数： 76309\n",
      "off_train和off_test的人数交集： 76307\n",
      "\n",
      "\n",
      "on_train的优惠券数： 27748\n",
      "off_train的优惠券数： 9739\n",
      "off_train领取优惠券的记录数： 1053282\n",
      "off_test的优惠券数： 2050\n",
      "off_test领取优惠券的记录数： 113640\n"
     ]
    }
   ],
   "source": [
    "print('on_train的人数：', len(set(on_train.User_id)))\n",
    "print('off_train的人数：', len(set(off_train.User_id)))\n",
    "print('off_train和on_train的人数交集：', len(set(on_train.User_id) & set(off_train.User_id)))\n",
    "\n",
    "print('\\n')\n",
    "print('on_train的商户数：', len(set(on_train.Merchant_id)))\n",
    "print('off_train的商户数：', len(set(off_train.Merchant_id)))\n",
    "print('off_train和on_train的商户数交集：', len(set(on_train.Merchant_id) & set(off_train.Merchant_id)))\n",
    "\n",
    "print('\\n')\n",
    "print('on_train的优惠券数：', len(set(on_train.Coupon_id)))\n",
    "print('off_train的优惠券数：', len(set(off_train.Coupon_id)))\n",
    "print('off_train和on_train的优惠券数交集：', len(set(on_train.Coupon_id) & set(off_train.Coupon_id)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('off_test的人数：', len(set(off_test.User_id)))\n",
    "print('off_train和off_test的人数交集：', len(set(off_train.User_id) & set(off_test.User_id)))\n",
    "\n",
    "print('\\n')\n",
    "print('on_train的优惠券数：', on_train.Coupon_id.nunique())\n",
    "print('off_train的优惠券数：', off_train.Coupon_id.nunique())\n",
    "print('off_train领取优惠券的记录数：', off_train[off_train.Coupon_id != -1].shape[0])\n",
    "print('off_test的优惠券数：', off_test.Coupon_id.nunique())\n",
    "print('off_test领取优惠券的记录数：', off_test[off_test.Coupon_id != -1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     48
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test.shape: (113640, 6)\n",
      "df_train1.shape: (258446, 7)\n",
      "df_train2.shape: (137167, 7)\n",
      "0    235152\n",
      "1     23294\n",
      "Name: label, dtype: int64\n",
      "0    128094\n",
      "1      9073\n",
      "Name: label, dtype: int64\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "###原始数据加载###################################################\n",
    "on_train = pd.read_csv(input_path + 'ccf_online_stage1_train.csv')\n",
    "off_train = pd.read_csv(input_path + 'ccf_offline_stage1_train.csv')\n",
    "off_test = pd.read_csv(input_path + 'ccf_offline_stage1_test_revised.csv')\n",
    "\n",
    "#空值填-1\n",
    "on_train = on_train.fillna(-1)\n",
    "off_train = off_train.fillna(-1)\n",
    "off_test = off_test.fillna(-1)\n",
    "\n",
    "###数据集划分#####################################################\n",
    "###测试集数据\n",
    "df_test = off_test\n",
    "# df_test = df_test.groupby(['User_id']).apply(lambda x: x.sort_values('Date_received')).reset_index(drop=True)\n",
    "\n",
    "df_test_feat_offline = off_train[((off_train.Date_received != -1) & (off_train.Date_received >= 20160315) & (off_train.Date_received <= 20160630)) | \n",
    "                                 ((off_train.Date != -1) & (off_train.Date >= 20160315) & (off_train.Date <= 20160630))]\n",
    "df_test_feat_online = on_train[((on_train.Date_received != -1) & (on_train.Date_received >= 20160315) & (on_train.Date_received <= 20160630)) | \n",
    "                               ((on_train.Date != -1) & (on_train.Date >= 20160315) & (on_train.Date <= 20160630))]\n",
    "\n",
    "print('df_test.shape:', df_test.shape)\n",
    "\n",
    "\n",
    "###训练集_1数据\n",
    "df_train1 = off_train[(off_train.Date_received != -1) & (off_train.Date_received >= 20160515) & (off_train.Date_received <= 20160615)]\n",
    "# df_train1 = df_train1.groupby(['User_id']).apply(lambda x: x.sort_values('Date_received')).reset_index(drop=True)\n",
    "\n",
    "df_train1_feat_offline = off_train[((off_train.Date_received != -1) & (off_train.Date_received >= 20160201) & (off_train.Date_received <= 20160514)) | \n",
    "                                  ((off_train.Date != -1) & (off_train.Date >= 20160201) & (off_train.Date <= 20160514))]\n",
    "df_train1_feat_online = on_train[((on_train.Date_received != -1) & (on_train.Date_received >= 20160201) & (on_train.Date_received <= 20160514)) | \n",
    "                                ((on_train.Date != -1) & (on_train.Date >= 20160201) & (on_train.Date <= 20160514))]\n",
    "\n",
    "print('df_train1.shape:', df_train1.shape)\n",
    "\n",
    "###训练集_2数据\n",
    "df_train2 = off_train[(off_train.Date_received != -1) & (off_train.Date_received >= 20160414) & (off_train.Date_received <= 20160514)]\n",
    "# df_train2 = df_train2.groupby(['User_id']).apply(lambda x: x.sort_values('Date_received')).reset_index(drop=True)\n",
    "\n",
    "df_train2_feat_offline = off_train[((off_train.Date_received != -1) & (off_train.Date_received >= 20160101) & (off_train.Date_received <= 20160413)) | \n",
    "                                  ((off_train.Date != -1) & (off_train.Date >= 20160101) & (off_train.Date <= 20160413))]\n",
    "df_train2_feat_online = on_train[((on_train.Date_received != -1) & (on_train.Date_received >= 20160101) & (on_train.Date_received <= 20160413)) | \n",
    "                                ((on_train.Date != -1) & (on_train.Date >= 20160101) & (on_train.Date <= 20160413))]                                          \n",
    "\n",
    "print('df_train2.shape:', df_train2.shape)\n",
    "\n",
    "\n",
    "###时间格式转化、训练集打标签#####################################################\n",
    "###train1时间格式转化，打标签\n",
    "def time_convert(int_time):\n",
    "    if int_time != -1:\n",
    "        str_time = str(int(int_time))\n",
    "        year = int(str_time[0: 4])\n",
    "        month = int(str_time[4: 6])\n",
    "        day = int(str_time[6: 8])\n",
    "        datatime_time = datetime(year, month, day)\n",
    "    else:\n",
    "        datatime_time = -1\n",
    "    \n",
    "    return datatime_time\n",
    "\n",
    "df_train1['Date_received'] = df_train1.Date_received.apply(time_convert)  \n",
    "df_train1['Date'] = df_train1.Date.apply(time_convert)  \n",
    "\n",
    "df_train1['diff'] = df_train1.apply(lambda x: (x.Date - x.Date_received).days if x.Date != -1 else -1, axis=1)\n",
    "df_train1['label'] = df_train1['diff'].apply(lambda x: 0 if(x > 15 or x == -1) else 1)\n",
    "\n",
    "print(df_train1['label'].value_counts())\n",
    "\n",
    "###train2时间格式转化，打标签\n",
    "df_train2['Date_received'] = df_train2.Date_received.apply(time_convert)  \n",
    "df_train2['Date'] = df_train2.Date.apply(time_convert)  \n",
    "\n",
    "df_train2['diff'] = df_train2.apply(lambda x: (x.Date - x.Date_received).days if x.Date != -1 else -1, axis=1)\n",
    "df_train2['label'] = df_train2['diff'].apply(lambda x: 0 if(x > 15 or x == -1) else 1)\n",
    "\n",
    "print(df_train2['label'].value_counts())\n",
    "\n",
    "###test时间格式转化\n",
    "df_test['Date_received'] = df_test.Date_received.apply(time_convert)\n",
    "\n",
    "\n",
    "\n",
    "###预处理完的数据保存#######################################################\n",
    "pickle.dump(df_test, open(input_path + 'df_test.pkl', 'wb'))\n",
    "pickle.dump(df_test_feat_offline, open(input_path + 'df_test_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_test_feat_online, open(input_path + 'df_test_feat_online.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(df_train1, open(input_path + 'df_train1.pkl', 'wb'))\n",
    "pickle.dump(df_train1_feat_offline, open(input_path + 'df_train1_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_train1_feat_online, open(input_path + 'df_train1_feat_online.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(df_train2, open(input_path + 'df_train2.pkl', 'wb'))\n",
    "pickle.dump(df_train2_feat_offline, open(input_path + 'df_train2_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_train2_feat_online, open(input_path + 'df_train2_feat_online.pkl', 'wb'))\n",
    "\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     1,
     15,
     24,
     33,
     46,
     90,
     144,
     206,
     235,
     268,
     288,
     320,
     334,
     379,
     393
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取特征的时间为: 171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(258446, 98)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(137167, 98)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(113640, 95)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "def discount_rate_trans(str_rate):\n",
    "    if str_rate == 'fixed':\n",
    "        float_rate = 0.9\n",
    "    else:\n",
    "        list_ = re.findall('\\d*', str_rate)\n",
    "        a = int(list_[0])\n",
    "        b = int(list_[2])\n",
    "\n",
    "        if a != 0: \n",
    "            float_rate = (a - b) / a\n",
    "        else:\n",
    "            float_rate = float(str_rate)\n",
    "    \n",
    "    return float_rate\n",
    "def discount_rate_man(str_rate):\n",
    "    if re.search(':', str_rate):\n",
    "        list_ = re.findall('\\d*', str_rate)\n",
    "        a = int(list_[0])\n",
    "        b = int(list_[2])\n",
    "        \n",
    "        return a\n",
    "    else:\n",
    "        return 0\n",
    "def discount_rate_jian(str_rate):\n",
    "    if re.search(':', str_rate):\n",
    "        list_ = re.findall('\\d*', str_rate)\n",
    "        a = int(list_[0])\n",
    "        b = int(list_[2])\n",
    "        \n",
    "        return b\n",
    "    else:\n",
    "        return 0\n",
    "def time_convert(int_time):\n",
    "    if int_time != -1:\n",
    "        str_time = str(int(int_time))\n",
    "        year = int(str_time[0: 4])\n",
    "        month = int(str_time[4: 6])\n",
    "        day = int(str_time[6: 8])\n",
    "        datatime_time = datetime(year, month, day)\n",
    "    else:\n",
    "        datatime_time = -1\n",
    "    \n",
    "    return datatime_time\n",
    "\n",
    "###六大特征群\n",
    "def user_off_feat(df_train1, df_train1_feat_offline):\n",
    "    #用户领取优惠券的次数：\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Date_received != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['user_received_coupon_count'])\n",
    "\n",
    "    #用户领取优惠券，但没有消费的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date == -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['user_received_coupon_butNotConsume_count'])\n",
    "\n",
    "    #用户领取优惠券，而且消费了的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['user_received_coupon_andConsume_count'])\n",
    "\n",
    "    #用户领取优惠券后的核销率：\n",
    "    df_train1['user_received_coupon_ConsumeRate'] = df_train1.user_received_coupon_andConsume_count / df_train1.user_received_coupon_count\n",
    "\n",
    "    #用户核销优惠券的平均折扣率，最大折扣率，最小折扣率 ：\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_tem_feat['Discount_rate'] = df_tem_feat.Discount_rate.apply(discount_rate_trans)\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['User_id'], ['Discount_rate'], ['user_consume_coupon_aveDiscountRate'], na=-1)\n",
    "    df_train1 = feat_max(df_train1, df_tem_feat, ['User_id'], ['Discount_rate'], ['user_consume_coupon_maxDiscountRate'], na=-1)\n",
    "    df_train1 = feat_min(df_train1, df_tem_feat, ['User_id'], ['Discount_rate'], ['user_consume_coupon_minDiscountRate'], na=-1)\n",
    "\n",
    "    #用户核销过优惠券的不同商家数量；以及占所有商家的比重：\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['User_id'], ['Merchant_id'], ['user_consume_coupon_MerchantNunique'])\n",
    "    df_train1['user_consume_coupon_MerchantRate'] = df_train1['user_consume_coupon_MerchantNunique'] / df_tem_feat.Merchant_id.nunique()\n",
    "\n",
    "    #用户核销过的不同优惠券数量；以及占所有核销优惠券的比重：\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['user_consume_coupon_Nunique'])\n",
    "    df_train1['user_consume_coupon_Rate'] = df_train1['user_consume_coupon_Nunique'] / df_train1['user_received_coupon_andConsume_count']\n",
    "\n",
    "    #用户平均核销每个商家多少张优惠券：\n",
    "    df_train1['user_consume_coupon_AveCount'] = df_train1['user_received_coupon_andConsume_count'] / df_train1['user_consume_coupon_MerchantNunique']\n",
    "\n",
    "    #用户核销优惠券中，离商家的平均距离，最远距离，最近距离\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)& \n",
    "                                         (df_train1_feat_offline.Distance != -1)].copy()\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['User_id'], ['Distance'], ['user_consume_coupon_meanDistance'], na=-1)\n",
    "    df_train1 = feat_max(df_train1, df_tem_feat, ['User_id'], ['Distance'], ['user_consume_coupon_maxDistance'], na=-1)\n",
    "    df_train1 = feat_min(df_train1, df_tem_feat, ['User_id'], ['Distance'], ['user_consume_coupon_minDistance'], na=-1)\n",
    "\n",
    "    return df_train1\n",
    "def user_on_feat(df_train1, df_train1_feat_online):\n",
    "    #用户线上消费次数：\n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_Consume_count'])\n",
    "    \n",
    "    #用户线上不消费次数：\n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action != 1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_notConsume_count'])\n",
    "    \n",
    "    #用户线上点击次数，购买次数，领取次数；点击率，购买率，领取率\n",
    "    df_tem_feat = df_train1_feat_online.copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_all_count'])\n",
    "    \n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 0].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_0_count'])\n",
    "    \n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_1_count'])\n",
    "    \n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 2].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_2_count'])\n",
    "    \n",
    "    df_train1['on_user_action_0_rate'] = df_train1['on_user_action_0_count'] / df_train1['on_user_action_all_count']\n",
    "    df_train1['on_user_action_1_rate'] = df_train1['on_user_action_1_count'] / df_train1['on_user_action_all_count']\n",
    "    df_train1['on_user_action_2_rate'] = df_train1['on_user_action_2_count'] / df_train1['on_user_action_all_count']\n",
    "    \n",
    "    #用户线上优惠券的（领取+核销）次数：\n",
    "    df_tem_feat = df_train1_feat_online[(df_train1_feat_online.Coupon_id != -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['on_user_Coupon_receive_count'])\n",
    "    \n",
    "    #用户线上优惠券核销的次数：\n",
    "    df_tem_feat = df_train1_feat_online[(df_train1_feat_online.Coupon_id != -1) & (df_train1_feat_online.Action == 1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_Coupon_andConsume_count'])\n",
    "    \n",
    "    #用户线上优惠券核销率：\n",
    "    df_train1['on_user_received_Consume_rate'] = df_train1['on_user_action_Consume_count'] / (df_train1['on_user_Coupon_receive_count'] + 0.1)\n",
    "    \n",
    "    #用户线下不消费的次数，占线上线下总的不消费次数比重\n",
    "    df_train1['on_notConsume_rate'] = df_train1['user_received_coupon_butNotConsume_count'] / \\\n",
    "                 (df_train1['user_received_coupon_butNotConsume_count'] + df_train1['on_user_action_notConsume_count'] + 0.1)\n",
    "\n",
    "    #用户线下优惠券核销次数，占线上线下总的优惠券核销次数比重\n",
    "    df_train1['on_coupon_Consume_rate'] = df_train1['user_received_coupon_andConsume_count'] / \\\n",
    "                 (df_train1['user_received_coupon_andConsume_count'] + df_train1['on_user_Coupon_andConsume_count'] + 0.1)\n",
    "\n",
    "    #用户线上领取优惠券的次数\n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 2].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['on_user_received_coupon_count'])\n",
    "    \n",
    "    #用户线下领取优惠券次数，占线上线下领取次数的比重\n",
    "    df_train1['on_received_coupon_rate'] = df_train1['user_received_coupon_count'] / \\\n",
    "                 (df_train1['user_received_coupon_count'] + df_train1['on_user_received_coupon_count'] + 0.1)\n",
    "    \n",
    "    return df_train1\n",
    "def Merchant_feat(df_train1, df_train1_feat_offline):\n",
    "    #商家优惠券发放次数\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Coupon_id != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_count'])\n",
    "    \n",
    "    #商家优惠券发放的种类\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Coupon_id != -1].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_nunique'])\n",
    "    \n",
    "    #商家优惠券发放后，不被核销的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != 1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_butNotConsume_count'])\n",
    "    \n",
    "    #商家优惠券发放后，被核销的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_andConsume_count'])\n",
    "\n",
    "    #商家优惠券发放后，被核销的比率：\n",
    "    df_train1['Merchant_send_coupon_andConsume_rate'] = df_train1['Merchant_send_coupon_andConsume_count'] / \\\n",
    "                                                        df_train1['Merchant_send_coupon_count']\n",
    "    \n",
    "    #商家优惠券核销的平均折率，最大折率，最小折率\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_tem_feat['Discount_rate'] = df_tem_feat.Discount_rate.apply(discount_rate_trans)\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['Merchant_id'], ['Discount_rate'], ['Merchant_coupon_Consume_aveDiscountRate'], na=-1)\n",
    "    df_train1 = feat_max(df_train1, df_tem_feat, ['Merchant_id'], ['Discount_rate'], ['Merchant_coupon_Consume_maxDiscountRate'], na=-1)\n",
    "    df_train1 = feat_min(df_train1, df_tem_feat, ['Merchant_id'], ['Discount_rate'], ['Merchant_coupon_Consume_minDiscountRate'], na=-1)\n",
    "    \n",
    "    #核销商家优惠券的，不同用户数量；以及占所有领取次数的比重\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['Merchant_id'], ['User_id'], ['Merchant_send_coupon_userNunique'])\n",
    "    df_train1['Merchant_send_coupon_userRate'] = df_train1['Merchant_send_coupon_userNunique'] / df_train1['Merchant_send_coupon_count']\n",
    "    \n",
    "    #商家平均每个用户核销优惠券多少张\n",
    "    df_train1['Merchant_aveUser_CouponCount'] = df_train1['Merchant_send_coupon_andConsume_count'] / df_train1['Merchant_send_coupon_userNunique']\n",
    "    \n",
    "    #商家被核销过的不同优惠券数量；\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_andConsume_nunique'])\n",
    "    \n",
    "    \n",
    "    #商家被核销过的不同优惠券数量，占所有领取过的不同优惠券比重\n",
    "    df_train1['Merchant_send_coupon_andConsume_nunique'] = df_train1['Merchant_send_coupon_andConsume_nunique'] / \\\n",
    "                                                               df_train1['Merchant_send_coupon_nunique']\n",
    "    \n",
    "    #商家平均每种优惠券核销多少张：\n",
    "    df_train1['Merchant_aveCoupon_count'] = df_train1['Merchant_send_coupon_andConsume_count'] / df_train1['Merchant_send_coupon_nunique']\n",
    "    \n",
    "    #商家被核销的优惠券中，平均，最大，最小距离。\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['Merchant_id'], ['Distance'], ['Merchant_send_coupon_meanDistance'], na=-1)\n",
    "    df_train1 = feat_max(df_train1, df_tem_feat, ['Merchant_id'], ['Distance'], ['Merchant_send_coupon_maxDistance'], na=-1)\n",
    "    df_train1 = feat_min(df_train1, df_tem_feat, ['Merchant_id'], ['Distance'], ['Merchant_send_coupon_minDistance'], na=-1)\n",
    "    \n",
    "    #商家被核销的优惠券中，核销的平均时间\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_tem_feat.Date = df_tem_feat.Date.apply(time_convert)\n",
    "    df_tem_feat.Date_received = df_tem_feat.Date_received.apply(time_convert)\n",
    "    df_tem_feat['diff'] = (df_tem_feat.Date - df_tem_feat.Date_received).dt.days\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['Merchant_id'], ['diff'], ['Merchant_coupon_Consume_AveTime'], na=-1)\n",
    "    \n",
    "    return df_train1\n",
    "def user_Merchant_feat(df_train1, df_train1_feat_offline):\n",
    "    #用户领取商家优惠券的次数\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Date_received != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id', 'Merchant_id'], ['Coupon_id'], ['user_get_Merchant_coupon_count'])\n",
    "    \n",
    "    #用户领取商家优惠券后，但不核销的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date == -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id', 'Merchant_id'], ['Coupon_id'], ['user_get_Merchant_coupon_notConsume_count'])\n",
    "    \n",
    "    #用户领取商家优惠券后，核销的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id', 'Merchant_id'], ['Coupon_id'], ['user_get_Merchant_coupon_Consume_count'])\n",
    "    \n",
    "    #用户领取商家优惠券后，核销率\n",
    "    df_train1['user_get_Merchant_coupon_Consume_rate'] = df_train1['user_get_Merchant_coupon_Consume_count'] / df_train1['user_get_Merchant_coupon_count']\n",
    "    \n",
    "    #用户对每个商家的不核销次数，占用户总的不核销次数的比重：\n",
    "    df_train1['userMerchant_notConsume_to_user_notConsume_rate'] = df_train1['user_get_Merchant_coupon_notConsume_count'] / df_train1['user_received_coupon_butNotConsume_count']\n",
    "    \n",
    "    #用户对每个商家的核销次数，占用户总的核销次数的比重：\n",
    "    df_train1['userMerchant_Consume_to_user_Consume_rate'] = df_train1['user_get_Merchant_coupon_Consume_count'] / df_train1['user_received_coupon_andConsume_count']\n",
    "    \n",
    "    #用户对每个商家的不核销次数，占商家总的不核销次数的比重：\n",
    "    df_train1['userMerchant_notConsume_to_Merchant_notConsume_rate'] = df_train1['user_get_Merchant_coupon_notConsume_count'] / df_train1['Merchant_send_coupon_butNotConsume_count']\n",
    "    \n",
    "    #用户对每个商家的核销次数，占商家总的核销次数的比重：\n",
    "    df_train1['userMerchant_Consume_to_Merchant_Consume_rate'] = df_train1['user_get_Merchant_coupon_Consume_count'] / df_train1['Merchant_send_coupon_andConsume_count']\n",
    "    \n",
    "    return df_train1\n",
    "def Coupon_feat(df_train1, df_train1_feat_offline):\n",
    "    df_train1['discount_rate_type'] = df_train1.Discount_rate.apply(lambda x: 0 if re.search(':', x) else 1)\n",
    "    df_train1['discount_rate_man'] = df_train1.Discount_rate.apply(discount_rate_man)\n",
    "    df_train1['discount_rate_jian'] = df_train1.Discount_rate.apply(discount_rate_jian)\n",
    "    df_train1['Discount_rate'] = df_train1.Discount_rate.apply(discount_rate_trans)\n",
    "    df_train1['day'] = df_train1.Date_received.dt.day\n",
    "    df_train1['weekday'] = df_train1.Date_received.dt.weekday\n",
    "    df_train1['is_weekend'] = df_train1.weekday.apply(lambda x: 1 if x<=4 else 0)\n",
    "    \n",
    "    #该优惠券在，历史上出现的次数：\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Coupon_id != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Coupon_id'], ['Merchant_id'], ['Coupon_appear_count'])\n",
    "    \n",
    "    #该优惠券在，历史上核销的次数：\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & df_train1_feat_offline.Date != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Coupon_id'], ['Merchant_id'], ['Coupon_Consume_count'])\n",
    "    \n",
    "    #该优惠券在，历史上的核销率：\n",
    "    df_train1['Coupon_Consume_rate'] = df_train1['Coupon_Consume_count'] / (df_train1['Coupon_appear_count'] + 0.1)\n",
    "\n",
    "    #历史上，该用户领取该优惠券的次数\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Coupon_id != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Coupon_id', 'User_id'], ['Merchant_id'], ['Coupon_User_appear_count'])\n",
    "    \n",
    "    #历史上，该用户领取该优惠券后的核销次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & df_train1_feat_offline.Date != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Coupon_id', 'User_id'], ['Merchant_id'], ['Coupon_User_Consume_count'])\n",
    "    \n",
    "    #历史上，该用户领取该优惠券后的核销率\n",
    "    df_train1['Coupon_User_Consume_rate'] = df_train1['Coupon_User_Consume_count'] / (df_train1['Coupon_User_appear_count'] + 0.1)\n",
    "    \n",
    "    \n",
    "    return df_train1\n",
    "def leakage_feat(df_train1):\n",
    "    #用户领取的所有优惠券数目\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['User_id'], ['Coupon_id'], ['leak_User_receive_all_Coupon_count'])\n",
    "    \n",
    "    #用户领取的相同优惠券数目\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['User_id', 'Coupon_id'], ['Merchant_id'], ['leak_User_receive_same_Coupon_count'])\n",
    "    \n",
    "    #用户领取同一优惠券的最大/最小时间： \n",
    "    df_train1_tem = df_train1.groupby(['User_id', 'Coupon_id'])['Merchant_id'].count().reset_index().rename(columns={'Merchant_id': 'count'})\n",
    "    df_train1_tem = df_train1_tem[df_train1_tem['count'] >= 2]\n",
    "    df_train1_tem = pd.merge(df_train1, df_train1_tem, on=['User_id', 'Coupon_id'], how='inner')\n",
    "    df_train1_tem['time'] = df_train1_tem['Date_received'].dt.day\n",
    "    \n",
    "    df_train1 = feat_max(df_train1, df_train1_tem, ['User_id', 'Coupon_id'], ['time'], ['leak_User_receive_same_Coupon_maxTime'])\n",
    "    df_train1 = feat_min(df_train1, df_train1_tem, ['User_id', 'Coupon_id'], ['time'], ['leak_User_receive_same_Coupon_minTime'])\n",
    "    \n",
    "    #是否是最后一次领取，是否是第一次领取：\n",
    "    df_train1['is_last_receive'] = df_train1['leak_User_receive_same_Coupon_maxTime'] - (df_train1['Date_received']).dt.day\n",
    "    df_train1['is_first_receive'] = (df_train1['Date_received']).dt.day - df_train1['leak_User_receive_same_Coupon_minTime']\n",
    "    \n",
    "    def is_firstOrLast_day(diff_day):\n",
    "        if diff_day == 0:\n",
    "            return 1\n",
    "        elif diff_day > 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    df_train1['is_last_receive'] = df_train1['is_last_receive'].apply(is_firstOrLast_day)\n",
    "    df_train1['is_first_receive'] = df_train1['is_first_receive'].apply(is_firstOrLast_day)\n",
    "    \n",
    "    #用户当天领取的优惠券总数：\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['User_id', 'Date_received'], ['Coupon_id'], ['leak_User_theDate_received_Coupon_count'])\n",
    "    \n",
    "    #用户当天领取相同优惠券总数：\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['User_id', 'Date_received', 'Coupon_id'], ['Merchant_id'], ['leak_User_theDate_received_Coupon_count'])\n",
    "    \n",
    "    #用户领取不同商家数目：\n",
    "    df_train1 = feat_nunique(df_train1, df_train1, ['User_id'], ['Merchant_id'], ['leak_User_receive_Merchant_nunique'])\n",
    "    \n",
    "    #用户领取的所有优惠券种类\n",
    "    df_train1 = feat_nunique(df_train1, df_train1, ['User_id'], ['Coupon_id'], ['leak_User_receive_Coupon_nunique'])\n",
    "\n",
    "    #商家被领取的优惠券数目：\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['Merchant_id'], ['Coupon_id'], ['leak_Merchant_send_Coupon_count'])\n",
    "\n",
    "    #商家被多少不用用户领取：\n",
    "    df_train1 = feat_nunique(df_train1, df_train1, ['Merchant_id'], ['User_id'], ['leak_Merchant_get_User_nunique'])\n",
    "    \n",
    "    #商家发行的所有优惠券种类：\n",
    "    df_train1 = feat_nunique(df_train1, df_train1, ['Merchant_id'], ['Coupon_id'], ['leak_Merchant_send_Coupon_nunique'])\n",
    "    \n",
    "    #同一张优惠券，用户这次领取与上一次/下一次领取的时间间隔：（超级强特）\n",
    "    def get_day_gap_before(the_DateReceived_all_DateReceived):\n",
    "        the_DateReceived, all_DateReceived = the_DateReceived_all_DateReceived.split('-')\n",
    "        all_DateReceived = all_DateReceived.split(':')\n",
    "\n",
    "        gaps = []\n",
    "        for day in all_DateReceived:\n",
    "            the_gap = (datetime(int(the_DateReceived[0: 4]), int(the_DateReceived[4: 6]), int(the_DateReceived[6: 8])) - \n",
    "                       datetime(int(day[0: 4]), int(day[4: 6]), int(day[6: 8]))).days\n",
    "            if the_gap > 0:\n",
    "                gaps.append(the_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "    def get_day_gap_after(the_DateReceived_all_DateReceived):\n",
    "        the_DateReceived, all_DateReceived = the_DateReceived_all_DateReceived.split('-')\n",
    "        all_DateReceived = all_DateReceived.split(':')\n",
    "\n",
    "        gaps = []\n",
    "        for day in all_DateReceived:\n",
    "            the_gap = (datetime(int(day[0: 4]), int(day[4: 6]), int(day[6: 8])) - \n",
    "                       datetime(int(the_DateReceived[0: 4]), int(the_DateReceived[4: 6]), int(the_DateReceived[6: 8]))).days\n",
    "            if the_gap > 0:\n",
    "                gaps.append(the_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "    df_train1_tem = df_train1.copy()\n",
    "    df_train1_tem['Date_received'] = df_train1_tem['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem = df_train1_tem.groupby(['User_id', 'Coupon_id'])['Date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    df_train1_tem = df_train1_tem.rename(columns={'Date_received': 'all_DateReceived'})\n",
    "\n",
    "    df_train1_tem_2 = pd.merge(df_train1, df_train1_tem, on=['User_id', 'Coupon_id'], how='left')\n",
    "    df_train1_tem_2['Date_received'] = df_train1_tem_2['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem_2['the_DateReceived_all_DateReceived'] = df_train1_tem_2.Date_received + '-' + df_train1_tem_2.all_DateReceived\n",
    "    df_train1_tem_2['receive_same_Coupon_timeGap_before'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_day_gap_before)\n",
    "    df_train1_tem_2['receive_same_Coupon_timeGap_after'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_day_gap_after)\n",
    "    df_train1_tem_2 = df_train1_tem_2[['receive_same_Coupon_timeGap_before', 'receive_same_Coupon_timeGap_after']]\n",
    "    \n",
    "    df_train1 = pd.concat([df_train1.reset_index(drop=True), df_train1_tem_2.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #用户这次领取与上一次/下一次领取的时间间隔：\n",
    "    df_train1_tem = df_train1.copy()\n",
    "    df_train1_tem['Date_received'] = df_train1_tem['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem = df_train1_tem.groupby(['User_id'])['Date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    df_train1_tem = df_train1_tem.rename(columns={'Date_received': 'all_DateReceived'})\n",
    "    \n",
    "    df_train1_tem_2 = pd.merge(df_train1, df_train1_tem, on=['User_id'], how='left')\n",
    "    df_train1_tem_2['Date_received'] = df_train1_tem_2['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem_2['the_DateReceived_all_DateReceived'] = df_train1_tem_2.Date_received + '-' + df_train1_tem_2.all_DateReceived\n",
    "    df_train1_tem_2['receive_Coupon_timeGap_before'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_day_gap_before)\n",
    "    df_train1_tem_2['receive_Coupon_timeGap_after'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_day_gap_after)\n",
    "    df_train1_tem_2 = df_train1_tem_2[['receive_Coupon_timeGap_before', 'receive_Coupon_timeGap_after']]\n",
    "    \n",
    "    df_train1 = pd.concat([df_train1.reset_index(drop=True), df_train1_tem_2.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    \n",
    "    #同一张优惠券，用户此次之前/之后领取的所有优惠券数目：\n",
    "    def get_Coupon_count_before(the_DateReceived_all_DateReceived):\n",
    "        the_DateReceived, all_DateReceived = the_DateReceived_all_DateReceived.split('-')\n",
    "        all_DateReceived = all_DateReceived.split(':')\n",
    "\n",
    "        gaps = []\n",
    "        for day in all_DateReceived:\n",
    "            the_gap = (datetime(int(the_DateReceived[0: 4]), int(the_DateReceived[4: 6]), int(the_DateReceived[6: 8])) - \n",
    "                       datetime(int(day[0: 4]), int(day[4: 6]), int(day[6: 8]))).days\n",
    "            if the_gap > 0:\n",
    "                gaps.append(the_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return len(gaps)\n",
    "    def get_Coupon_count_after(the_DateReceived_all_DateReceived):\n",
    "        the_DateReceived, all_DateReceived = the_DateReceived_all_DateReceived.split('-')\n",
    "        all_DateReceived = all_DateReceived.split(':')\n",
    "\n",
    "        gaps = []\n",
    "        for day in all_DateReceived:\n",
    "            the_gap = (datetime(int(day[0: 4]), int(day[4: 6]), int(day[6: 8])) - \n",
    "                       datetime(int(the_DateReceived[0: 4]), int(the_DateReceived[4: 6]), int(the_DateReceived[6: 8]))).days\n",
    "            if the_gap > 0:\n",
    "                gaps.append(the_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return len(gaps)\n",
    "    df_train1_tem = df_train1.copy()\n",
    "    df_train1_tem['Date_received'] = df_train1_tem['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem = df_train1_tem.groupby(['User_id', 'Coupon_id'])['Date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    df_train1_tem = df_train1_tem.rename(columns={'Date_received': 'all_DateReceived'})\n",
    "\n",
    "    df_train1_tem_2 = pd.merge(df_train1, df_train1_tem, on=['User_id', 'Coupon_id'], how='left')\n",
    "    df_train1_tem_2['Date_received'] = df_train1_tem_2['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem_2['the_DateReceived_all_DateReceived'] = df_train1_tem_2.Date_received + '-' + df_train1_tem_2.all_DateReceived\n",
    "    df_train1_tem_2['receive_sameCoupon_count_before'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_Coupon_count_before)\n",
    "    df_train1_tem_2['receive_sameCoupon_count_after'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_Coupon_count_after)\n",
    "    df_train1_tem_2 = df_train1_tem_2[['receive_sameCoupon_count_before', 'receive_sameCoupon_count_after']]\n",
    "    \n",
    "    df_train1 = pd.concat([df_train1.reset_index(drop=True), df_train1_tem_2.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #用户此次之前/之后领取的所有优惠券数目：\n",
    "    df_train1_tem = df_train1.copy()\n",
    "    df_train1_tem['Date_received'] = df_train1_tem['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem = df_train1_tem.groupby(['User_id'])['Date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    df_train1_tem = df_train1_tem.rename(columns={'Date_received': 'all_DateReceived'})\n",
    "    \n",
    "    df_train1_tem_2 = pd.merge(df_train1, df_train1_tem, on=['User_id'], how='left')\n",
    "    df_train1_tem_2['Date_received'] = df_train1_tem_2['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem_2['the_DateReceived_all_DateReceived'] = df_train1_tem_2.Date_received + '-' + df_train1_tem_2.all_DateReceived\n",
    "    df_train1_tem_2['receive_Coupon_count_before'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_Coupon_count_before)\n",
    "    df_train1_tem_2['receive_Coupon_count_after'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_Coupon_count_after)\n",
    "    df_train1_tem_2 = df_train1_tem_2[['receive_Coupon_count_before', 'receive_Coupon_count_after']]\n",
    "    \n",
    "    df_train1 = pd.concat([df_train1.reset_index(drop=True), df_train1_tem_2.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    \n",
    "    return df_train1\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "if __name__ =='__main__':\n",
    "    ###数据加载###############################\n",
    "    df_test = pickle.load(open(input_path + 'df_test.pkl', 'rb'))\n",
    "    df_test_feat_offline = pickle.load(open(input_path + 'df_test_feat_offline.pkl', 'rb'))\n",
    "    df_test_feat_online = pickle.load(open(input_path + 'df_test_feat_online.pkl', 'rb'))\n",
    "\n",
    "    df_train1 = pickle.load(open(input_path + 'df_train1.pkl', 'rb'))\n",
    "    df_train1_feat_offline = pickle.load(open(input_path + 'df_train1_feat_offline.pkl', 'rb'))\n",
    "    df_train1_feat_online = pickle.load(open(input_path + 'df_train1_feat_online.pkl', 'rb'))\n",
    "\n",
    "    df_train2 = pickle.load(open(input_path + 'df_train2.pkl', 'rb'))\n",
    "    df_train2_feat_offline = pickle.load(open(input_path + 'df_train2_feat_offline.pkl', 'rb'))\n",
    "    df_train2_feat_online = pickle.load(open(input_path + 'df_train2_feat_online.pkl', 'rb'))\n",
    "    \n",
    "    \n",
    "    start_time = time()\n",
    "    ##########用户线下特征群；线上得分（0.5218），线下得分（0.5800）\n",
    "    df_train1 = user_off_feat(df_train1, df_train1_feat_offline)\n",
    "    df_train2 = user_off_feat(df_train2, df_train2_feat_offline)\n",
    "    df_test = user_off_feat(df_test, df_test_feat_offline)\n",
    "\n",
    "    ########用户线上特征群；线上得分（0.5992），线下得分（）\n",
    "    df_train1 = user_on_feat(df_train1, df_train1_feat_online)\n",
    "    df_train2 = user_on_feat(df_train2, df_train2_feat_online)\n",
    "    df_test = user_on_feat(df_test, df_test_feat_online)\n",
    "\n",
    "    ########商店特征群；线上得分（0.5998），线下得分（0.5781）\n",
    "    df_train1 = Merchant_feat(df_train1, df_train1_feat_offline)\n",
    "    df_train2 = Merchant_feat(df_train2, df_train2_feat_offline)\n",
    "    df_test = Merchant_feat(df_test, df_test_feat_offline)\n",
    "    \n",
    "    ########用户商家交互特征群；\n",
    "    df_train1 = user_Merchant_feat(df_train1, df_train1_feat_offline)\n",
    "    df_train2 = user_Merchant_feat(df_train2, df_train2_feat_offline)\n",
    "    df_test = user_Merchant_feat(df_test, df_test_feat_offline)\n",
    "\n",
    "    #########优惠券特征群；线上得分（）\n",
    "    df_train1 = Coupon_feat(df_train1, df_train1_feat_offline)\n",
    "    df_train2 = Coupon_feat(df_train2, df_train2_feat_offline)\n",
    "    df_test = Coupon_feat(df_test, df_test_feat_offline)\n",
    "    \n",
    "    ##########leakage特征群；线上得分（0.7683），线下得分（0.7504）\n",
    "    df_train1 = leakage_feat(df_train1)\n",
    "    df_train2 = leakage_feat(df_train2)\n",
    "    df_test = leakage_feat(df_test)\n",
    "    \n",
    "\n",
    "    print('提取特征的时间为:', int(time() - start_time))\n",
    "    \n",
    "    df_train1.shape\n",
    "    df_train2.shape\n",
    "    df_test.shape\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 跑模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 20%随机验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###训练集、验证集############\n",
    "X_train1 = df_train1.drop(['label', 'Date_received', 'Date', 'diff', 'User_id', 'Merchant_id'], axis=1)\n",
    "y_train1 = df_train1['label']\n",
    "\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train1, y_train1, test_size=0.2, random_state=1254)\n",
    "df_Coupon_y = pd.concat([X_val_.Coupon_id, y_val_], axis=1)\n",
    "\n",
    "# 奇怪，为什么id特征加进去分数提高那么多，是leak吗？？\n",
    "X_train = X_train1.drop(['Coupon_id'], axis=1)\n",
    "X_train_ = X_train_.drop(['Coupon_id'], axis=1)\n",
    "X_val_ = X_val_.drop(['Coupon_id'], axis=1)\n",
    "\n",
    "\n",
    "###测试集###################\n",
    "X_test = df_test.drop(['User_id', 'Merchant_id', 'Coupon_id',  'Date_received',], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     1,
     3,
     19,
     23
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[904]\tvalid_0's binary_logloss: 0.183722\n",
      "平均auc为： 0.8017468961530861\n",
      "训练预测的时间为: 40\n"
     ]
    }
   ],
   "source": [
    "###模型训练预测\n",
    "def clf_train(X_train, y_train, X_val, y_val):\n",
    "    categorical_feature = ['性别', '入院科室']\n",
    "    clf = lgb.LGBMClassifier(n_estimators=10000,\n",
    "                                   learning_rate=0.06,\n",
    "                                   max_depth=5,\n",
    "                                   num_leaves=30,\n",
    "                                   objective='binary',\n",
    "                                   subsample=0.8,\n",
    "                                   sub_feature=0.8,\n",
    "#                                    class_weight='balanced',  #设置样本平衡；好像不要会更好\n",
    "                                   )\n",
    "    clf.fit(X_train, y_train, \n",
    "            eval_set=[(X_val, y_val)], eval_metric='binary_logloss',\n",
    "            early_stopping_rounds=100, verbose = 5000,\n",
    "#             categorical_feature = categorical_feature    #onehot之后就不需要了\n",
    "            )\n",
    "    feat_impo = sorted(zip(X_train.columns, clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "    return clf, feat_impo \n",
    "def clf_predict(clf, X_val):\n",
    "    y_pred = clf.predict_proba(X_val, num_iteration=clf.best_iteration)\n",
    "    \n",
    "    return y_pred\n",
    "def clf_evaluate(df_Coupon_y, y_pred):\n",
    "    y_pred = y_pred[:, 1]  #因为sklearn输出每个类别的概率，手动选择1类\n",
    "    \n",
    "    df_val_auc = df_Coupon_y[['Coupon_id', 'label']]\n",
    "    df_val_auc['pred_prob'] = y_pred\n",
    "\n",
    "    # 计算平均AUC\n",
    "    vg = df_val_auc.groupby(['Coupon_id'])\n",
    "    aucs = []\n",
    "    for i in vg:   #这个“i”是分好组子集\n",
    "        df_tem = i[1]\n",
    "\n",
    "        if len(df_tem['label'].unique()) != 2:\n",
    "            continue\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(df_tem['label'], df_tem['pred_prob'], pos_label=1)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    print('平均auc为：', np.average(aucs))\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "clf, feat_impo = clf_train(X_train_, y_train_, X_val_, y_val_)\n",
    "y_pred = clf_predict(clf, X_val_)\n",
    "clf_evaluate(df_Coupon_y, y_pred)\n",
    "\n",
    "print('训练预测的时间为:', int(time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 划分数据集做验证集\n",
    "训练集：train2；验证集train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137167, 91)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(258446, 91)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(113640, 91)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1 = df_train1.drop(['Date_received', 'User_id', 'Coupon_id', 'Merchant_id', 'Date', 'diff', 'label'], axis=1)\n",
    "y_train1 = df_train1['label']\n",
    "\n",
    "X_train2 = df_train2.drop(['Date_received', 'User_id', 'Coupon_id', 'Merchant_id', 'Date', 'diff', 'label'], axis=1)\n",
    "y_train2 = df_train2['label']\n",
    "\n",
    "X_test = df_test.drop(['Date_received', 'User_id', 'Coupon_id', 'Merchant_id'], axis=1)\n",
    "\n",
    "\n",
    "X_train2.shape\n",
    "X_train1.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     1,
     3,
     12,
     20,
     24
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.231941\n",
      "[200]\tvalid_0's binary_logloss: 0.233949\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.231472\n",
      "平均auc为： 0.7504008583682287\n",
      "训练预测的时间为: 15\n"
     ]
    }
   ],
   "source": [
    "###模型训练预测\n",
    "def clf_train(X_train, y_train, X_val, y_val):\n",
    "    categorical_feature = ['性别', '入院科室']\n",
    "    clf = lgb.LGBMClassifier(n_estimators=10000,\n",
    "                                   learning_rate=0.06,\n",
    "                                   max_depth=5,\n",
    "                                   num_leaves=30,\n",
    "                                   objective='binary',\n",
    "                                   subsample=0.9,\n",
    "                                   sub_feature=0.9,\n",
    "#                                    class_weight='balanced',  #设置样本平衡；好像不要会更好\n",
    "                                   )\n",
    "    clf.fit(X_train, y_train, \n",
    "            eval_set=[(X_val, y_val)], eval_metric='binary_logloss',\n",
    "            early_stopping_rounds=100, verbose = 100,\n",
    "#             categorical_feature = categorical_feature    #onehot之后就不需要了\n",
    "            )\n",
    "#     feat_impo = sorted(zip(X_train.columns, clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "    feat_impo = 1\n",
    "    return clf, feat_impo \n",
    "def clf_predict(clf, X_val):\n",
    "    y_pred = clf.predict_proba(X_val, num_iteration=clf.best_iteration)\n",
    "    \n",
    "    return y_pred\n",
    "def clf_evaluate(df_Coupon_y, y_pred):\n",
    "    y_pred = y_pred[:, 1]  #因为sklearn输出每个类别的概率，手动选择1类\n",
    "    \n",
    "    df_val_auc = df_Coupon_y[['Coupon_id', 'label']]\n",
    "    df_val_auc['pred_prob'] = y_pred\n",
    "\n",
    "    # 计算平均AUC\n",
    "    vg = df_val_auc.groupby(['Coupon_id'])\n",
    "    aucs = []\n",
    "    for i in vg:   #这个“i”是分好组子集\n",
    "        df_tem = i[1]\n",
    "\n",
    "        if len(df_tem['label'].unique()) != 2:\n",
    "            continue\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(df_tem['label'], df_tem['pred_prob'], pos_label=1)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    print('平均auc为：', np.average(aucs))\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "clf, feat_impo = clf_train(X_train2, y_train2, X_train1, y_train1)\n",
    "y_pred = clf_predict(clf, X_train1)\n",
    "clf_evaluate(df_train1, y_pred)\n",
    "\n",
    "print('训练预测的时间为:', int(time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线上提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     1,
     10
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def clf_train(X_train, y_train, X_val, y_val):\n",
    "    clf = lgb.LGBMClassifier(n_estimators=180,\n",
    "                             learning_rate=0.06,\n",
    "                             max_depth=5,\n",
    "                             num_leaves=30,\n",
    "                             objective='binary',\n",
    "                             subsample=0.9,\n",
    "                             sub_feature=0.9,\n",
    "#                            class_weight='balanced',  #设置样本平衡；好像不要会更好\n",
    "                             )\n",
    "    clf.fit(X_train, y_train, \n",
    "#             eval_set=[(X_val, y_val)], eval_metric='binary_logloss',\n",
    "#             early_stopping_rounds=100000, verbose = 5000,\n",
    "            )\n",
    "#     feat_impo = sorted(zip(X_train.columns, clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "    feat_impo = 1\n",
    "    return clf, feat_impo \n",
    "def clf_predict(clf, X_val):\n",
    "    y_pred = clf.predict_proba(X_val, num_iteration=180)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "###单分数据集\n",
    "clf, feat_impo = clf_train(X_train1, y_train1, X_train1, y_train1)\n",
    "y_pred = clf_predict(clf, X_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "submission = pd.read_csv(input_path + 'ccf_offline_stage1_test_revised.csv')[['User_id', 'Coupon_id', 'Date_received']]  #df_test['']是datetime格式，当然是不行的啦！\n",
    "df_tem = pd.DataFrame(y_pred, columns=['Probability'])\n",
    "submission = pd.concat([submission, df_tem], axis=1)\n",
    "\n",
    "submission.to_csv(submi_path + '8_12_all_恢复原来保证不错误.csv', index =False, header=None)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 可能用到的代码保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    #用户此次之后/之前领取的所有优惠券数目：\n",
    "    def after_Coupon_count(df_user):\n",
    "        count = df_user.shape[0]\n",
    "        df_user['leak_after_User_receive_Coupon_count'] = list(range(count-1, -1, -1))\n",
    "        df_user['leak_pre_User_receive_Coupon_count'] = list(range(0, count))\n",
    "\n",
    "        return df_user\n",
    "    df_train1 = df_train1.groupby(['User_id']).apply(after_Coupon_count).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    #用户上一次/下一次领取的时间间隔：\n",
    "    def receive_Coupon_gap(df_user):\n",
    "        df_user['shift_up'] = df_user['Date_received'].shift(-1)\n",
    "        df_user['shift_down'] = df_user['Date_received'].shift(1)\n",
    "#         df_user['receive_Coupon_gap_pre'] = (df_user['Date_received'] - df_user['shift_down']).dt.days.fillna(-1)\n",
    "#         df_user['receive_Coupon_gap_after'] = (df_user['shift_up'] - df_user['Date_received']).dt.days.fillna(-1)\n",
    "\n",
    "        return df_user\n",
    "    df_train1 = df_train1.groupby(['User_id']).apply(receive_Coupon_gap).reset_index(drop=True)\n",
    "    df_train1 = df_train1.drop(['shift_up', 'shift_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train1 = pickle.load(open(input_path + 'df_train1.pkl', 'rb'))\n",
    "df_train1_tem = df_train1.copy()[0: 50]\n",
    "\n",
    "#用户上一次/下一次领取的时间间隔：\n",
    "def receive_Coupon_gap(df_user):\n",
    "    df_user['shift_up'] = df_user['Date_received'].shift(-1)\n",
    "    df_user['shift_down'] = df_user['Date_received'].shift(1)\n",
    "    df_user['receive_Coupon_gap_pre'] = (df_user['Date_received'] - df_user['shift_down']).dt.days.fillna(-1)\n",
    "    df_user['receive_Coupon_gap_after'] = (df_user['shift_up'] - df_user['Date_received']).dt.days.fillna(-1)\n",
    "    \n",
    "    global i\n",
    "    i += 1\n",
    "    if i%10000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    return df_user\n",
    "\n",
    "i = 0\n",
    "df_train1 = df_train1.groupby(['User_id']).apply(receive_Coupon_gap).reset_index(drop=True)\n",
    "df_train1 = df_train1.drop(['shift_up', 'shift_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#用户此次“之后”/“之前”领取的所有优惠券数目\n",
    "df_all_user_tem = pd.DataFrame(columns=['User_id', 'leak_after_User_receive_Coupon_count', 'leak_pre_User_receive_Coupon_count'])\n",
    "user_set = df_train1.User_id.unique()\n",
    "i = 0\n",
    "for user in user_set:\n",
    "    df_user_tem = df_train1[df_train1.User_id == user].copy()[['User_id']]\n",
    "    count = df_user_tem.shape[0]\n",
    "    df_user_tem['leak_after_User_receive_Coupon_count'] = list(range(count-1, -1, -1))\n",
    "    df_user_tem['leak_pre_User_receive_Coupon_count'] = list(range(0, count))\n",
    "    df_all_user_tem = pd.concat([df_all_user_tem, df_user_tem]).reset_index(drop=True)\n",
    "    i += 1\n",
    "    print(i)\n",
    "df_all_user_tem = df_all_user_tem.drop('User_id', axis=1)\n",
    "df_train1 = pd.concat([df_train1, df_all_user_tem], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = pickle.load(open(input_path + 'df_train.pkl', 'rb'))\n",
    "df_train.head()\n",
    "\n",
    "df_train_feat_offline = pickle.load(open(input_path + 'df_train_feat_offline.pkl', 'rb'))\n",
    "df_tem_feat = df_train_feat_offline[df_train_feat_offline.Date_received != -1]\n",
    "df_tem_feat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "pickle.dump(df_test, open(input_path + 'df_test.pkl', 'wb'))\n",
    "pickle.dump(df_test_feat_offline, open(input_path + 'df_test_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_test_feat_online, open(input_path + 'df_test_feat_online.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(df_train, open(input_path + 'df_train.pkl', 'wb'))\n",
    "pickle.dump(df_train_feat_offline, open(input_path + 'df_train_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_train_feat_online, open(input_path + 'df_train_feat_online.pkl', 'wb'))\n",
    "\n",
    "###数据加载###############################\n",
    "df_test = pickle.load(open(input_path + 'df_test.pkl', 'rb'))\n",
    "df_test_feat_offline = pickle.load(open(input_path + 'df_test_feat_offline.pkl', 'rb'))\n",
    "df_test_feat_online = pickle.load(open(input_path + 'df_test_feat_online.pkl', 'rb'))\n",
    "\n",
    "df_train = pickle.load(open(input_path + 'df_train.pkl', 'rb'))\n",
    "df_train_feat_offline = pickle.load(open(input_path + 'df_train_feat_offline.pkl', 'rb'))\n",
    "df_train_feat_online = pickle.load(open(input_path + 'df_train_feat_online.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ###转化为时间格式\n",
    "# on_train['Date_received'] = on_train.Date_received.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)   \n",
    "\n",
    "# off_train['Date_received'] = off_train.Date_received.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)   \n",
    "\n",
    "# off_test['Date_received'] = off_test.Date_received.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)   \n",
    "\n",
    "# on_train['Date'] = on_train.Date.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)   \n",
    "\n",
    "# off_train['Date'] = off_train.Date.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  2  3\n",
       "1  2  1  3\n",
       "2  7  8  3\n",
       "3  1  2  7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  4\n",
       "1  2  1\n",
       "2  7  8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>hahah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  hahah\n",
       "0  1      4\n",
       "1  2      1\n",
       "2  7      8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list = [[1,2,3],[2,1,3],[7,8,3],[1,2,7]]\n",
    "\n",
    "df = pd.DataFrame(a_list)\n",
    "df\n",
    "\n",
    "df.groupby([0])[[1]].sum().reset_index()\n",
    "\n",
    "grou = [0]\n",
    "stati = [1]\n",
    "name = ['hahah']\n",
    "df.groupby(grou)[stati].agg('sum').reset_index().rename(columns={stati[0]: name[0]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
